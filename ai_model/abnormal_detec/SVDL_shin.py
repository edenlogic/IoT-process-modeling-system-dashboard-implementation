# ===================================================================
# 1. model.py - ëª¨ë¸ êµ¬ì¡° ì •ì˜ (ì„œë¹™ìš©)
# ===================================================================

import torch
import torch.nn as nn

class LSTMModel(nn.Module):
    """
    ê¸°ê³„ ê³ ì¥ ì§„ë‹¨ìš© LSTM ëª¨ë¸
    
    ì‚¬ìš©ë²•:
    model = LSTMModel(input_dim=4, hidden_dim=128, num_layers=2, output_dim=5, dropout_rate=0.5)
    model.load_state_dict(torch.load("model.pth"))
    model.eval()
    output = model(input_tensor)
    """
    def __init__(self, input_dim, hidden_dim, num_layers, output_dim, dropout_rate):
        super(LSTMModel, self).__init__()
        self.hidden_dim = hidden_dim
        self.num_layers = num_layers

        self.lstm = nn.LSTM(
            input_dim, 
            hidden_dim, 
            num_layers, 
            batch_first=True, 
            dropout=dropout_rate if num_layers > 1 else 0
        )
        self.fc = nn.Linear(hidden_dim, output_dim)

    def forward(self, x):
        # x shape: (batch_size, sequence_length, input_dim)
        batch_size = x.size(0)
        
        # ì´ˆê¸° ì€ë‹‰ ìƒíƒœ ë° ì…€ ìƒíƒœ
        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(x.device)
        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(x.device)

        # LSTM forward
        lstm_out, _ = self.lstm(x, (h0, c0))
        
        # ë§ˆì§€ë§‰ íƒ€ì„ìŠ¤í…ì˜ ì¶œë ¥ ì‚¬ìš©
        out = self.fc(lstm_out[:, -1, :])
        
        return out


# ===================================================================
# 2. predict.py - ì„œë¹™ìš© ì¶”ë¡  í´ë˜ìŠ¤
# ===================================================================

import torch
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
import joblib

class FaultPredictor:
    """
    ê¸°ê³„ ê³ ì¥ ì§„ë‹¨ ì˜ˆì¸¡ê¸° - ì„œë¹™ìš©
    
    ì´ˆê¸°í™”:
    predictor = FaultPredictor()
    predictor.load_model("model.pth", "scaler.pkl")
    
    ì˜ˆì¸¡:
    result = predictor.predict(sensor_data)
    """
    
    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = None
        self.scaler = None
        
        # í´ë˜ìŠ¤ ì •ë³´
        self.class_names = [
            'normal', 
            'bearing_fault', 
            'roll_misalignment', 
            'motor_overload', 
            'lubricant_shortage'
        ]
        
        self.class_descriptions = {
            'normal': 'ì •ìƒ',
            'bearing_fault': 'ë² ì–´ë§ ê³ ì¥',
            'roll_misalignment': 'ë¡¤ ì •ë ¬ ë¶ˆëŸ‰',
            'motor_overload': 'ëª¨í„° ê³¼ë¶€í•˜',
            'lubricant_shortage': 'ìœ¤í™œìœ  ë¶€ì¡±'
        }
    

    def load_model(self, model_path, scaler_path=None):
        """
        ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
        
        Args:
            model_path (str): ëª¨ë¸ ê°€ì¤‘ì¹˜ íŒŒì¼ ê²½ë¡œ (.pth)
            scaler_path (str, optional): ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼ ê²½ë¡œ (.pkl)
        """
        # 1. ëª¨ë¸ êµ¬ì¡° ì •ì˜
        self.model = LSTMModel(
            input_dim=4,
            hidden_dim=128,
            num_layers=2,
            output_dim=5,
            dropout_rate=0.5
        )
        
        # 2. ê°€ì¤‘ì¹˜ ë¡œë“œ
        self.model.load_state_dict(torch.load(model_path, map_location=self.device))
        self.model.to(self.device)
        
        # 3. ì¶”ë¡  ëª¨ë“œ ì„¤ì •
        self.model.eval()
        
        # 4. ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ (ìˆëŠ” ê²½ìš°)
        if scaler_path:
            self.scaler = joblib.load(scaler_path)
        
        print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (Device: {self.device})")
    
    def preprocess_data(self, data):
        """
        ì…ë ¥ ë°ì´í„° ì „ì²˜ë¦¬
        
        Args:
            data: numpy array, pandas DataFrame, ë˜ëŠ” list
                  Shape: (sequence_length, 4) ë˜ëŠ” (batch_size, sequence_length, 4)
        
        Returns:
            torch.Tensor: (batch_size, sequence_length, 4)
        """
        # DataFrameì„ numpyë¡œ ë³€í™˜
        if isinstance(data, pd.DataFrame):
            data = data.values
        elif isinstance(data, list):
            data = np.array(data)
        
        # 2D â†’ 3D (ë°°ì¹˜ ì°¨ì› ì¶”ê°€)
        if len(data.shape) == 2:
            data = data[np.newaxis, :]  # (1, seq_len, features)
        
        # ì •ê·œí™” (ìŠ¤ì¼€ì¼ëŸ¬ê°€ ìˆëŠ” ê²½ìš°)
        if self.scaler is not None:
            batch_size, seq_len, n_features = data.shape
            data_2d = data.reshape(-1, n_features)
            data_scaled = self.scaler.transform(data_2d)
            data = data_scaled.reshape(batch_size, seq_len, n_features)
        
        # í…ì„œë¡œ ë³€í™˜
        tensor = torch.FloatTensor(data).to(self.device)
        return tensor
    
    def predict(self, data, temperature_scaling=1.0):
        """
        ê³ ì¥ ì§„ë‹¨ ì˜ˆì¸¡
        
        Args:
            data: ì„¼ì„œ ë°ì´í„° (sequence_length, 4) ë˜ëŠ” (batch_size, sequence_length, 4)
            temperature_scaling (float): í™•ë¥  ì¡°ì • íŒŒë¼ë¯¸í„°
        
        Returns:
            dict: ì˜ˆì¸¡ ê²°ê³¼
        """
        if self.model is None:
            raise RuntimeError("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load_model()ì„ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")
        
        # ì¶”ë¡  ëª¨ë“œ
        with torch.no_grad():
            # ì „ì²˜ë¦¬
            input_tensor = self.preprocess_data(data)
            
            # ëª¨ë¸ ì¶”ë¡ 
            output = self.model(input_tensor)
            
            # Temperature scaling ì ìš©
            scaled_output = output / temperature_scaling
            probabilities = torch.softmax(scaled_output, dim=1)
            
            # CPUë¡œ ì´ë™ ë° numpy ë³€í™˜
            probs_np = probabilities.cpu().numpy()
            
            # ë°°ì¹˜ ì²˜ë¦¬ (ì—¬ëŸ¬ ì‹œí€€ìŠ¤ì¸ ê²½ìš°)
            if probs_np.shape[0] == 1:
                # ë‹¨ì¼ ì‹œí€€ìŠ¤
                probs = probs_np[0]
            
                
                predicted_class = int(np.argmax(probs))
                
                result = {
                    'predicted_class': predicted_class,
                    'predicted_class_name': self.class_names[predicted_class],
                    'predicted_class_description': self.class_descriptions[self.class_names[predicted_class]],
                    'confidence': float(np.max(probs)),
                    'is_normal': predicted_class == 0,
                    'probabilities': {
                        name: float(prob) 
                        for name, prob in zip(self.class_names, probs)
                    },

                }
            else:
                # ë°°ì¹˜ ì²˜ë¦¬
                results = []
                for i in range(probs_np.shape[0]):
                    probs = probs_np[i]

                    predicted_class = int(np.argmax(probs))
                    
                    results.append({
                        'predicted_class': predicted_class,
                        'predicted_class_name': self.class_names[predicted_class],
                        'confidence': float(np.max(probs)),
                        'is_normal': predicted_class == 0,
                        'probabilities': {
                            name: float(prob) 
                            for name, prob in zip(self.class_names, probs)
                        }
                    })
                result = {'batch_results': results}
        
        return result

    def determine_alert_level(self, probabilities):
        """
        í™•ë¥  ë”•ì…”ë„ˆë¦¬ë¥¼ ë°›ì•„ì„œ ê²½ê³  ë ˆë²¨ ê²°ì •
        
        Args:
            probabilities: {
                'normal': 0.65,
                'bearing_fault': 0.20,
                'roll_misalignment': 0.10,
                'motor_overload': 0.03,
                'lubricant_shortage': 0.02
            }
        
        Returns:
            dict: {
                'alert_level': 'ì •ìƒ' | 'ëª¨ë‹ˆí„°ë§ í•„ìš”' | 'ì ê²€ í•„ìš”',
                'alert_color': 'green' | 'yellow' | 'red',
                'recommended_action': 'êµ¬ì²´ì ì¸ ì¡°ì¹˜ì‚¬í•­'
            }
        """
        
        # í™•ë¥  ê°’ë“¤ ì¶”ì¶œ
        normal_prob = probabilities.get('normal', 0.0)
        
        # ê³ ì¥ í™•ë¥ ë“¤ í•©ê³„
        fault_probs = {k: v for k, v in probabilities.items() if k != 'normal'}
        total_fault_prob = sum(fault_probs.values())
        
        # ê°€ì¥ ë†’ì€ ê³ ì¥ í™•ë¥ 
        if fault_probs:
            max_fault_type = max(fault_probs, key=fault_probs.get)
            max_fault_prob = fault_probs[max_fault_type]
        else:
            max_fault_type = None
            max_fault_prob = 0.0
        
        # ê³ ì¥ ìœ í˜• í•œê¸€ëª…
        fault_korean = {
            'bearing_fault': 'ë² ì–´ë§ ê³ ì¥',
            'roll_misalignment': 'ë¡¤ ì •ë ¬ ë¶ˆëŸ‰',
            'motor_overload': 'ëª¨í„° ê³¼ë¶€í•˜',
            'lubricant_shortage': 'ìœ¤í™œìœ  ë¶€ì¡±'
        }
        
        # ğŸ¯ ê²½ê³  ë ˆë²¨ ê²°ì •
        if normal_prob >= 0.8:
            # ì •ìƒ í™•ë¥  80% ì´ìƒ
            return {
                'alert_level': 'ì •ìƒ',
                'alert_color': 'green',
                'recommended_action': 'ì •ìƒ ìš´ì˜ ê³„ì†'
            }
        
        elif total_fault_prob >= 0.7 or max_fault_prob >= 0.7:
            # ê³ ì¥ í™•ë¥  í•©ê³„ 70% ì´ìƒ OR íŠ¹ì • ê³ ì¥ 70% ì´ìƒ
            fault_name = fault_korean.get(max_fault_type, 'ê³ ì¥')
            return {
                'alert_level': 'ì ê²€ í•„ìš”',
                'alert_color': 'red',
                'recommended_action': f'ì¦‰ì‹œ ì ê²€ í•„ìš” ({fault_name} ê°€ëŠ¥ì„± ë†’ìŒ)'
            }
        
        else:
            # ë‚˜ë¨¸ì§€ ëª¨ë“  ê²½ìš°
            if max_fault_prob >= 0.3:
                fault_name = fault_korean.get(max_fault_type, 'ê³ ì¥')
                action = f'ì£¼ì˜ ê´€ì°° ({fault_name} ì˜ì‹¬)'
            else:
                action = 'ì„¼ì„œ ë°ì´í„° ì§€ì† ëª¨ë‹ˆí„°ë§'
                
            return {
                'alert_level': 'ëª¨ë‹ˆí„°ë§ í•„ìš”',
                'alert_color': 'yellow',
                'recommended_action': action
            }


# ===================================================================
# 3. ì‚¬ìš© ì˜ˆì‹œ 
# ===================================================================

if __name__ == "__main__":
    
    # Step 1: ì´ˆê¸°í™”
    predictor = FaultPredictor()
    
    # Step 2: ëª¨ë¸ ë¡œë“œ
    predictor.load_model(
        model_path="trained_model.pth",
        scaler_path="scaler.pkl"  # ì—†ìœ¼ë©´ None
    )
    
    # Step 3: ì˜ˆì¸¡ ì‹¤í–‰
    sensor_data = np.random.randn(60, 4)  # ì‹¤ì œë¡œëŠ” ì‹¤ì‹œê°„ ì„¼ì„œ ë°ì´í„°
    result = predictor.predict(sensor_data)
    
    print("=== ì˜ˆì¸¡ ê²°ê³¼ ===")
    print(f"ì˜ˆì¸¡ í´ë˜ìŠ¤: {result['predicted_class_description']}")
    print(f"ì‹ ë¢°ë„: {result['confidence']:.2%}")
    print(f"ì •ìƒ ì—¬ë¶€: {'ì •ìƒ' if result['is_normal'] else 'ì´ìƒ'}")
    
    '''ë°°ì¹˜ ì˜ˆì¸¡ (ì—¬ëŸ¬ ì‹œí€€ìŠ¤ ë™ì‹œ ì²˜ë¦¬)
    batch_data = np.random.randn(5, 60, 4)  # 5ê°œ ì‹œí€€ìŠ¤
    batch_result = predictor.predict(batch_data)
    
    print("\n=== ë°°ì¹˜ ì˜ˆì¸¡ ê²°ê³¼ ===")
    for i, res in enumerate(batch_result['batch_results']):
        print(f"ì‹œí€€ìŠ¤ {i+1}: {res['predicted_class_name']} (ì‹ ë¢°ë„: {res['confidence']:.2%})")
    '''

    #í™•ë¥ ì´ ê·¹ë‹¨ì ì¼ ë•Œ Temperature Scaling
    if result['confidence'] > 0.95:
        print("\n=== Temperature Scaling ì ìš© ===")
        smooth_result = predictor.predict(sensor_data, temperature_scaling=2.0)
        print(f"ì¡°ì •ëœ ì‹ ë¢°ë„: {smooth_result['confidence']:.2%}")



    # ê°„ë‹¨í•œ ê²½ê³ 
    result = predictor.predict(sensor_data)

    # ê²½ê³  ë ˆë²¨ ê³„ì‚° (ì´ê²ƒë§Œ ì¶”ê°€í•˜ë©´ ë¨!)
    alert = predictor.determine_alert_level(result['probabilities'])

    # ì‚¬ìš©
    print(f"ìƒíƒœ: {alert['alert_level']}")
    print(f"ì¡°ì¹˜: {alert['recommended_action']}")

# ===================================================================
# 4. ì„¤ì¹˜ ë° ì‚¬ìš© ê°€ì´ë“œ
# ===================================================================

"""
ğŸš€ ì„¤ì¹˜ ë° ì‚¬ìš© ê°€ì´ë“œ

1. í•„ìš”í•œ íŒŒì¼:
   - trained_model.pth  (ëª¨ë¸ ê°€ì¤‘ì¹˜)
   - scaler.pkl         (ì •ê·œí™” ìŠ¤ì¼€ì¼ëŸ¬, ì„ íƒì‚¬í•­)
   - model.py           (ì´ íŒŒì¼)

2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜:
   pip install torch scikit-learn numpy pandas joblib

3. ê¸°ë³¸ ì‚¬ìš©ë²•:
   ```python
   from model import FaultPredictor
   
   # ì´ˆê¸°í™” ë° ëª¨ë¸ ë¡œë“œ
   predictor = FaultPredictor()
   predictor.load_model("trained_model.pth", "scaler.pkl")
   
   # ì˜ˆì¸¡ (ì„¼ì„œ ë°ì´í„°: 60ê°œ íƒ€ì„ìŠ¤í… x 4ê°œ ì„¼ì„œ)
   result = predictor.predict(sensor_data)
   print(result['predicted_class_name'])  # ì˜ˆ: 'bearing_fault'
   print(result['confidence'])            # ì˜ˆ: 0.85
   ```

4. ì£¼ì˜ì‚¬í•­:
   - ì…ë ¥ ë°ì´í„° í˜•íƒœ: (60, 4) ë˜ëŠ” (batch_size, 60, 4)
   - ì„¼ì„œ ìˆœì„œ: [Temperature, Machine Speed, Vibration Level, Energy Consumption]
   - GPU ìˆìœ¼ë©´ ìë™ ì‚¬ìš©, ì—†ìœ¼ë©´ CPU ì‚¬ìš©
"""